<!DOCTYPE HTML>
<html lang="en">

<head>
  <title>Junhwa Hur</title>

  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">

  <meta name="author" content="Junhwa Hur" />
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="/style.css" />
  <link rel="canonical" href="http://localhost:4000/">
  <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr style="padding:0px">
            <td style="padding:2.5%;width:70%;vertical-align:middle">
              <h1>
                Junhwa Hur
              </h1>
              <p>Hello! I am a research scientist at Google DeepMind in Cambridge, MA, USA. I received my Ph.D. at <a href="http://www.tu-darmstadt.de/index.en.jsp">Technische Universität Darmstadt</a>, where I was supervised by <a href="https://www.visinf.tu-darmstadt.de/visual_inference/people_vi/stefan_roth.en.jsp">Prof. Stefan Roth Ph.D.</a> at <a href="https://www.visinf.tu-darmstadt.de/visual_inference/index.en.jsp">Visual Inference group</a>. I received my M.Sc. at Seoul National University and B.Sc. at POSTECH.
              </p>
              <p style="text-align:center">
                <a href="mailto:junhwa.hur@gmail.com">Email</a> &nbsp;/&nbsp;
                <a href="/pdfs/cv.pdf">CV</a>  &nbsp;/&nbsp;
                <a href="https://scholar.google.com/citations?user=z4dNJdkAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                <a href="https://github.com/hurjunhwa">Github</a> &nbsp;/&nbsp;
                <a href="https://www.linkedin.com/in/junhwa-hur"> LinkedIn </a>
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/profile_img.png">
            </td>
          </tr>
        </table>

<!-- News -->
<!--         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>News</h2>
              <ul>
              <li>09/2022: Our paper on surround-view depth estimation has been accepted at NeurIPS 2022.</li>
              <li>06/2022: Our paper on robotic grasping for multiple general real-world objects has been accepted at IROS 2022.</li>
              <li>05/2022: Chosen as one of 157 outstanding reviewers of CVPR 2022.</li>
              <li>05/2022: Successfully defended my Ph.D. dissertation!</li></ul>
            </td>
          </tr>
        </table> -->

<!-- Academic Service -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Academic Service </h2>
              <p>
                • Area chair: ECCV 2024, CVPR 2025, ICCV 2025, NeurIPS 2025 <br>
                • Outstanding reviewer awards: CVPR (2018, 2019, 2020, 2022, 2024), NeurIPS (2023), ICCV (2021), ECCV (2020), ACCV (2020)
              </p>
            </td>
          </tr>
        </table>

<!-- Research -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.0%;width:22%;vertical-align:middle;min-width:180px">
              <h2>Research </h2>
            </td>
          </tr>
          
          <tr onmouseout="hifi_stop()" onmouseover="hifi_start()">
            <td style="padding:2.0%;width:22%;vertical-align:middle;min-width:180px">
              <div class="one" style="width:auto; height:auto; max-width:100%; position: relative;">
                <img src="/images/2025/2025_hifi.png" width="160" style="display: block; width: 100%; height: auto;">
                <div class="two" id="hifi_mouseover" style="width:100%; height:100%; position: absolute; top: 0; left: 0; opacity: 0; transition: opacity 0.3s ease-in-out;">
                  
                    <img src="/images/2025/2025_hifi.png" width="160" style="display: block; width: 100%; height: auto;">
                  
                </div>
              </div>

              <script type="text/javascript">
                function hifi_start() {
                  const mouseoverDiv = document.getElementById('hifi_mouseover');
                  if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "1";

                  
                }

                function hifi_stop() {
                  const mouseoverDiv = document.getElementById('hifi_mouseover');
                   if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "0";

                  // Only try to pause video if video_over exists for this post
                  
                }
                // Initial call to ensure the mouseover content is hidden on page load
                hifi_stop();
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="https://diffusion-vision.github.io/"><h3>High-Resolution Frame Interpolation with Patch-based Cascaded Diffusion</h3></a>
              <br>
              <b>Junhwa Hur</b>*, Charles Herrmann*, Saurabh Saxena, Janne Kontkanen, Wei-Sheng (Jason) Lai, Yichang Shih, Michael Rubinstein, David J. Fleet, Deqing Sun
              <br>
              <em>*Equal contribution</em><br>
              <em>AAAI</em>, 2025
              <br>
              <a href="https://arxiv.org/abs/2410.11838">paper</a> / 
              <a href="https://arxiv.org/abs/2410.11838">arxiv</a> / 
              <a href="https://hifi-diffusion.github.io/">project</a>
              

            </td>
          </tr>
        
          <tr onmouseout="lumiere_stop()" onmouseover="lumiere_start()">
            <td style="padding:2.0%;width:22%;vertical-align:middle;min-width:180px">
              <div class="one" style="width:auto; height:auto; max-width:100%; position: relative;">
                <img src="/images/2024/2024_lumiere.jpg" width="160" style="display: block; width: 100%; height: auto;">
                <div class="two" id="lumiere_mouseover" style="width:100%; height:100%; position: absolute; top: 0; left: 0; opacity: 0; transition: opacity 0.3s ease-in-out;">
                  
                    <video width="160" height="auto" muted loop preload="auto" style="display: block; width: 100%; height: auto;">
                      <source src="/images/2024/2024_lumiere.mp4" type="video/mp4">
                      Your browser does not support the video tag.
                    </video>
                  
                </div>
              </div>

              <script type="text/javascript">
                function lumiere_start() {
                  const mouseoverDiv = document.getElementById('lumiere_mouseover');
                  if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "1";

                  
                    const videoElement = mouseoverDiv.querySelector('video');
                    if (videoElement) {videoElement.play();}
                  
                }

                function lumiere_stop() {
                  const mouseoverDiv = document.getElementById('lumiere_mouseover');
                   if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "0";

                  // Only try to pause video if video_over exists for this post
                  
                    const videoElement = mouseoverDiv.querySelector('video');
                    if (videoElement) {
                      videoElement.pause();
                      // Optional: Reset video to the beginning when paused
                      // videoElement.currentTime = 0;
                    }
                  
                }
                // Initial call to ensure the mouseover content is hidden on page load
                lumiere_stop();
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="https://lumiere-video.github.io/"><h3>Lumiere: A Space-Time Diffusion Model for Video Generation</h3></a>
              <br>
              Omer Bar-Tal, Hila Chefer, Omer Tov, Charles Herrmann, Roni Paiss, Shiran Zada, Ariel Ephrat, <b>Junhwa Hur</b>, Guanghui Liu, Amit Raj, Yuanzhen Li, Michael Rubinstein, Tomer Michaeli, Oliver Wang, Deqing Sun, Tali Dekel, Inbar Mosseri
              <br>
              
              <em>SIGGRAPH Asia 2024</em>, 2024
              <br>
              <a href="https://dl.acm.org/doi/full/10.1145/3680528.3687614">paper</a> / 
              <a href="https://arxiv.org/abs/2401.12945">arxiv</a> / 
              <a href="https://lumiere-video.github.io/">project</a>
              

            </td>
          </tr>
        
          <tr onmouseout="telling_left_from_right_stop()" onmouseover="telling_left_from_right_start()">
            <td style="padding:2.0%;width:22%;vertical-align:middle;min-width:180px">
              <div class="one" style="width:auto; height:auto; max-width:100%; position: relative;">
                <img src="/images/2024/2024_leftright_a.png" width="160" style="display: block; width: 100%; height: auto;">
                <div class="two" id="telling_left_from_right_mouseover" style="width:100%; height:100%; position: absolute; top: 0; left: 0; opacity: 0; transition: opacity 0.3s ease-in-out;">
                  
                    <img src="/images/2024/2024_leftright_b.png" width="160" style="display: block; width: 100%; height: auto;">
                  
                </div>
              </div>

              <script type="text/javascript">
                function telling_left_from_right_start() {
                  const mouseoverDiv = document.getElementById('telling_left_from_right_mouseover');
                  if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "1";

                  
                }

                function telling_left_from_right_stop() {
                  const mouseoverDiv = document.getElementById('telling_left_from_right_mouseover');
                   if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "0";

                  // Only try to pause video if video_over exists for this post
                  
                }
                // Initial call to ensure the mouseover content is hidden on page load
                telling_left_from_right_stop();
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="https://telling-left-from-right.github.io/"><h3>Telling Left from Right: Identifying Geometry-Aware Semantic Correspondence</h3></a>
              <br>
              Junyi Zhang, Charles Herrmann, <b>Junhwa Hur</b>, Eric Chen, Varun Jampani, Deqing Sun, and Ming-Hsuan Yang
              <br>
              
              <em>NeurIPS</em>, 2024
              <br>
              <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_Telling_Left_from_Right_Identifying_Geometry-Aware_Semantic_Correspondence_CVPR_2024_paper.pdf">paper</a> / 
              <a href="https://arxiv.org/abs/2311.17034">arxiv</a> / 
              <a href="https://telling-left-from-right.github.io/">project</a>
              

            </td>
          </tr>
        
          <tr onmouseout="wonderjourney_stop()" onmouseover="wonderjourney_start()">
            <td style="padding:2.0%;width:22%;vertical-align:middle;min-width:180px">
              <div class="one" style="width:auto; height:auto; max-width:100%; position: relative;">
                <img src="images/2024/2024_wonderjourney.png" width="160" style="display: block; width: 100%; height: auto;">
                <div class="two" id="wonderjourney_mouseover" style="width:100%; height:100%; position: absolute; top: 0; left: 0; opacity: 0; transition: opacity 0.3s ease-in-out;">
                  
                    <video width="160" height="auto" muted loop preload="auto" style="display: block; width: 100%; height: auto;">
                      <source src="images/2024/2024_wonderjourney.mp4" type="video/mp4">
                      Your browser does not support the video tag.
                    </video>
                  
                </div>
              </div>

              <script type="text/javascript">
                function wonderjourney_start() {
                  const mouseoverDiv = document.getElementById('wonderjourney_mouseover');
                  if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "1";

                  
                    const videoElement = mouseoverDiv.querySelector('video');
                    if (videoElement) {videoElement.play();}
                  
                }

                function wonderjourney_stop() {
                  const mouseoverDiv = document.getElementById('wonderjourney_mouseover');
                   if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "0";

                  // Only try to pause video if video_over exists for this post
                  
                    const videoElement = mouseoverDiv.querySelector('video');
                    if (videoElement) {
                      videoElement.pause();
                      // Optional: Reset video to the beginning when paused
                      // videoElement.currentTime = 0;
                    }
                  
                }
                // Initial call to ensure the mouseover content is hidden on page load
                wonderjourney_stop();
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="https://kovenyu.com/WonderJourney"><h3>WonderJourney: Going from Anywhere to Everywhere</h3></a>
              <br>
              Hong-Xing Yu, Haoyi Duan, <b>Junhwa Hur</b>, Kyle Sargent, Michael Rubinstein, William T. Freeman, Forrester Cole, Deqing Sun, Noah Snavely, Jiajun Wu, Charles Herrmann
              <br>
              
              <em>CVPR</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2312.03884">paper</a> / 
              <a href="https://arxiv.org/abs/2312.03884">arxiv</a> / 
              <a href="https://kovenyu.com/WonderJourney">project</a>
              

            </td>
          </tr>
        
          <tr onmouseout="boundaryattention_stop()" onmouseover="boundaryattention_start()">
            <td style="padding:2.0%;width:22%;vertical-align:middle;min-width:180px">
              <div class="one" style="width:auto; height:auto; max-width:100%; position: relative;">
                <img src="/images/2024/2024_boundaryattention_a.png" width="160" style="display: block; width: 100%; height: auto;">
                <div class="two" id="boundaryattention_mouseover" style="width:100%; height:100%; position: absolute; top: 0; left: 0; opacity: 0; transition: opacity 0.3s ease-in-out;">
                  
                    <img src="/images/2024/2024_boundaryattention_b.png" width="160" style="display: block; width: 100%; height: auto;">
                  
                </div>
              </div>

              <script type="text/javascript">
                function boundaryattention_start() {
                  const mouseoverDiv = document.getElementById('boundaryattention_mouseover');
                  if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "1";

                  
                }

                function boundaryattention_stop() {
                  const mouseoverDiv = document.getElementById('boundaryattention_mouseover');
                   if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "0";

                  // Only try to pause video if video_over exists for this post
                  
                }
                // Initial call to ensure the mouseover content is hidden on page load
                boundaryattention_stop();
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="https://boundaryattention.github.io/"><h3>Boundary Attention: Learning Curves, Corners, Junctions and Grouping</h3></a>
              <br>
              Mia Gaia Polansky, Charles Herrmann, <b>Junhwa Hur</b>, Deqing Sun, Dor Verbin, Todd Zickler
              <br>
              
              <em>ECCVW</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2401.00935">paper</a> / 
              <a href="https://arxiv.org/abs/2401.00935">arxiv</a> / 
              <a href="https://boundaryattention.github.io/">project</a>
              

            </td>
          </tr>
        
          <tr onmouseout="dmd_stop()" onmouseover="dmd_start()">
            <td style="padding:2.0%;width:22%;vertical-align:middle;min-width:180px">
              <div class="one" style="width:auto; height:auto; max-width:100%; position: relative;">
                <img src="/images/2024/2024_dmd_a.jpg" width="160" style="display: block; width: 100%; height: auto;">
                <div class="two" id="dmd_mouseover" style="width:100%; height:100%; position: absolute; top: 0; left: 0; opacity: 0; transition: opacity 0.3s ease-in-out;">
                  
                    <img src="/images/2024/2024_dmd_b.jpg" width="160" style="display: block; width: 100%; height: auto;">
                  
                </div>
              </div>

              <script type="text/javascript">
                function dmd_start() {
                  const mouseoverDiv = document.getElementById('dmd_mouseover');
                  if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "1";

                  
                }

                function dmd_stop() {
                  const mouseoverDiv = document.getElementById('dmd_mouseover');
                   if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "0";

                  // Only try to pause video if video_over exists for this post
                  
                }
                // Initial call to ensure the mouseover content is hidden on page load
                dmd_stop();
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="https://diffusion-vision.github.io/dmd/"><h3>Zero-Shot Metric Depth with a Field-of-View Conditioned Diffusion Model</h3></a>
              <br>
              Saurabh Saxena, <b>Junhwa Hur</b>, Charles Herrmann, Deqing Sun, and David J. Fleet
              <br>
              
              <em>ECCVW</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2312.13252">paper</a> / 
              <a href="https://arxiv.org/abs/2312.13252">arxiv</a> / 
              <a href="https://diffusion-vision.github.io/dmd/">project</a>
              

            </td>
          </tr>
        
          <tr onmouseout="ddvm_stop()" onmouseover="ddvm_start()">
            <td style="padding:2.0%;width:22%;vertical-align:middle;min-width:180px">
              <div class="one" style="width:auto; height:auto; max-width:100%; position: relative;">
                <img src="/images/2023/2023_ddvm_a.jpg" width="160" style="display: block; width: 100%; height: auto;">
                <div class="two" id="ddvm_mouseover" style="width:100%; height:100%; position: absolute; top: 0; left: 0; opacity: 0; transition: opacity 0.3s ease-in-out;">
                  
                    <img src="/images/2023/2023_ddvm_b.gif" width="160" style="display: block; width: 100%; height: auto;">
                  
                </div>
              </div>

              <script type="text/javascript">
                function ddvm_start() {
                  const mouseoverDiv = document.getElementById('ddvm_mouseover');
                  if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "1";

                  
                }

                function ddvm_stop() {
                  const mouseoverDiv = document.getElementById('ddvm_mouseover');
                   if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "0";

                  // Only try to pause video if video_over exists for this post
                  
                }
                // Initial call to ensure the mouseover content is hidden on page load
                ddvm_stop();
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="https://diffusion-vision.github.io/"><h3>The Surprising Effectiveness of Diffusion Models for Optical Flow and Monocular Depth Estimation</h3></a>
              <br>
              Saurabh Saxena, Charles Herrmann, <b>Junhwa Hur</b>, Abhishek Kar, Mohammad Norouzi, Deqing Sun, and David J. Fleet
              <br>
              
              <em>NeurIPS</em>, 2023<font color="#FA4841"><b>&nbsp;&nbsp;Oral presentation</b></font>
              <br>
              <a href="https://arxiv.org/abs/2306.01923">paper</a> / 
              <a href="https://arxiv.org/abs/2306.01923">arxiv</a> / 
              <a href="https://diffusion-vision.github.io/">project</a>
              

            </td>
          </tr>
        
          <tr onmouseout="sddino_stop()" onmouseover="sddino_start()">
            <td style="padding:2.0%;width:22%;vertical-align:middle;min-width:180px">
              <div class="one" style="width:auto; height:auto; max-width:100%; position: relative;">
                <img src="/images/2023/2023_sddino_a.jpg" width="160" style="display: block; width: 100%; height: auto;">
                <div class="two" id="sddino_mouseover" style="width:100%; height:100%; position: absolute; top: 0; left: 0; opacity: 0; transition: opacity 0.3s ease-in-out;">
                  
                    <img src="/images/2023/2023_sddino_b.jpg" width="160" style="display: block; width: 100%; height: auto;">
                  
                </div>
              </div>

              <script type="text/javascript">
                function sddino_start() {
                  const mouseoverDiv = document.getElementById('sddino_mouseover');
                  if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "1";

                  
                }

                function sddino_stop() {
                  const mouseoverDiv = document.getElementById('sddino_mouseover');
                   if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "0";

                  // Only try to pause video if video_over exists for this post
                  
                }
                // Initial call to ensure the mouseover content is hidden on page load
                sddino_stop();
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="https://sd-complements-dino.github.io/"><h3>A Tale of Two Features: Stable Diffusion Complements DINO for Zero-Shot Semantic Correspondence</h3></a>
              <br>
              Junyi Zhang, Charles Herrmann, <b>Junhwa Hur</b>, Luisa Polania Cabrera, Varun Jampani, Deqing Sun, and Ming-Hsuan Yang
              <br>
              
              <em>NeurIPS</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2305.15347">paper</a> / 
              <a href="https://sd-complements-dino.github.io/sd_dino_files/Appendix.pdf">supp</a> / 
              <a href="https://arxiv.org/abs/2305.15347">arxiv</a> / 
              <a href="https://sd-complements-dino.github.io/">project</a> / 
              <a href="https://github.com/Junyi42/sd-dino">code</a>
              

            </td>
          </tr>
        
          <tr onmouseout="saf_stop()" onmouseover="saf_start()">
            <td style="padding:2.0%;width:22%;vertical-align:middle;min-width:180px">
              <div class="one" style="width:auto; height:auto; max-width:100%; position: relative;">
                <img src="/images/2023/2023_saf_a.jpg" width="160" style="display: block; width: 100%; height: auto;">
                <div class="two" id="saf_mouseover" style="width:100%; height:100%; position: absolute; top: 0; left: 0; opacity: 0; transition: opacity 0.3s ease-in-out;">
                  
                    <img src="/images/2023/2023_saf_b.jpg" width="160" style="display: block; width: 100%; height: auto;">
                  
                </div>
              </div>

              <script type="text/javascript">
                function saf_start() {
                  const mouseoverDiv = document.getElementById('saf_mouseover');
                  if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "1";

                  
                }

                function saf_stop() {
                  const mouseoverDiv = document.getElementById('saf_mouseover');
                   if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "0";

                  // Only try to pause video if video_over exists for this post
                  
                }
                // Initial call to ensure the mouseover content is hidden on page load
                saf_stop();
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Self-Supervised_AutoFlow_CVPR_2023_paper.pdf"><h3>Self-supervised AutoFlow</h3></a>
              <br>
              Hsin-Ping Huang, Charles Herrmann, <b>Junhwa Hur</b>, Erika Lu, Kyle Sargent, Austin Stone, Ming-Hsuan Yang, and Deqing Sun
              <br>
              
              <em>CVPR</em>, 2023
              <br>
              <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Self-Supervised_AutoFlow_CVPR_2023_paper.pdf">paper</a> / 
              <a href="https://openaccess.thecvf.com/content/CVPR2023/supplemental/Huang_Self-Supervised_AutoFlow_CVPR_2023_supplemental.pdf">supp</a> / 
              <a href="https://arxiv.org/abs/2212.01762">arxiv</a> / 
              <a href="https://autoflow-google.github.io">code</a>
              <p>Self-supervised AutoFlow learns to generate an optical flow training set through self-supervision on the target domain.</p>

            </td>
          </tr>
        
          <tr onmouseout="raftmsf_stop()" onmouseover="raftmsf_start()">
            <td style="padding:2.0%;width:22%;vertical-align:middle;min-width:180px">
              <div class="one" style="width:auto; height:auto; max-width:100%; position: relative;">
                <img src="/images/2022/2022_raftmsf_a.jpg" width="160" style="display: block; width: 100%; height: auto;">
                <div class="two" id="raftmsf_mouseover" style="width:100%; height:100%; position: absolute; top: 0; left: 0; opacity: 0; transition: opacity 0.3s ease-in-out;">
                  
                    <img src="/images/2022/2022_raftmsf_b.jpg" width="160" style="display: block; width: 100%; height: auto;">
                  
                </div>
              </div>

              <script type="text/javascript">
                function raftmsf_start() {
                  const mouseoverDiv = document.getElementById('raftmsf_mouseover');
                  if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "1";

                  
                }

                function raftmsf_stop() {
                  const mouseoverDiv = document.getElementById('raftmsf_mouseover');
                   if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "0";

                  // Only try to pause video if video_over exists for this post
                  
                }
                // Initial call to ensure the mouseover content is hidden on page load
                raftmsf_stop();
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="https://arxiv.org/abs/2205.01568"><h3>RAFT-MSF: Self-Supervised Monocular Scene Flow Using Recurrent Optimizer</h3></a>
              <br>
              Bayram Bayramli, <b>Junhwa Hur</b>, and Hongtao Lu
              <br>
              
              <em>IJCV</em>, 2023
              <br>
              <a href="https://doi.org/10.1007/s11263-023-01828-4">paper</a> / 
              <a href="https://arxiv.org/abs/2205.01568">arxiv</a>
              <p>For self-supervised monocular scene flow, our RAFT-backbone-based approach significantly improves the scene flow accuracy and even outperforms a semi-supervised method.</p>

            </td>
          </tr>
        
          <tr onmouseout="surrounddepth_stop()" onmouseover="surrounddepth_start()">
            <td style="padding:2.0%;width:22%;vertical-align:middle;min-width:180px">
              <div class="one" style="width:auto; height:auto; max-width:100%; position: relative;">
                <img src="/images/2022/2022_vf.jpg" width="160" style="display: block; width: 100%; height: auto;">
                <div class="two" id="surrounddepth_mouseover" style="width:100%; height:100%; position: absolute; top: 0; left: 0; opacity: 0; transition: opacity 0.3s ease-in-out;">
                  
                    <img src="/images/2022/2022_vf.gif" width="160" style="display: block; width: 100%; height: auto;">
                  
                </div>
              </div>

              <script type="text/javascript">
                function surrounddepth_start() {
                  const mouseoverDiv = document.getElementById('surrounddepth_mouseover');
                  if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "1";

                  
                }

                function surrounddepth_stop() {
                  const mouseoverDiv = document.getElementById('surrounddepth_mouseover');
                   if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "0";

                  // Only try to pause video if video_over exists for this post
                  
                }
                // Initial call to ensure the mouseover content is hidden on page load
                surrounddepth_stop();
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="https://openreview.net/forum?id=0PfIQs-ttQQ"><h3>Self-Supervised Surround-View Depth Estimation with Volumetric Feature Fusion</h3></a>
              <br>
              Jung Hee Kim*, <b>Junhwa Hur</b>*, Tien Phuoc Nguyen, and Seong-Gyun Jeong
              <br>
              <em>*Equal contribution</em><br>
              <em>NeurIPS</em>, 2022
              <br>
              <a href="https://openreview.net/forum?id=0PfIQs-ttQQ">paper</a> / 
              <a href="https://github.com/42dot/VFDepth">code</a>
              <p>Our voxel-based approach to surround-view depth estimation improves metric-scale depth accuracy and can synthesize a depth map at arbitrary rotated views.</p>

            </td>
          </tr>
        
          <tr onmouseout="phddissertation_stop()" onmouseover="phddissertation_start()">
            <td style="padding:2.0%;width:22%;vertical-align:middle;min-width:180px">
              <div class="one" style="width:auto; height:auto; max-width:100%; position: relative;">
                <img src="/images/2022/2022_diss.jpg" width="160" style="display: block; width: 100%; height: auto;">
                <div class="two" id="phddissertation_mouseover" style="width:100%; height:100%; position: absolute; top: 0; left: 0; opacity: 0; transition: opacity 0.3s ease-in-out;">
                  
                    <img src="/images/2022/2022_diss.gif" width="160" style="display: block; width: 100%; height: auto;">
                  
                </div>
              </div>

              <script type="text/javascript">
                function phddissertation_start() {
                  const mouseoverDiv = document.getElementById('phddissertation_mouseover');
                  if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "1";

                  
                }

                function phddissertation_stop() {
                  const mouseoverDiv = document.getElementById('phddissertation_mouseover');
                   if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "0";

                  // Only try to pause video if video_over exists for this post
                  
                }
                // Initial call to ensure the mouseover content is hidden on page load
                phddissertation_stop();
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="https://tuprints.ulb.tu-darmstadt.de/21624/"><h3>Joint Motion, Semantic Segmentation, Occlusion, and Depth Estimation</h3></a>
              <br>
              <b>Junhwa Hur</b>
              <br>
              
              <em>Ph.D. Dissertation, Technische Universität Darmstadt</em>, 2022
              <br>
              <a href="https://tuprints.ulb.tu-darmstadt.de/21624/">paper</a>
              <p>In this dissertation, we propose how to jointly formulate multiple tasks for scene understanding and what kind of benefits can be obtained from the joint estimation.</p>

            </td>
          </tr>
        
          <tr onmouseout="maskgrasp_stop()" onmouseover="maskgrasp_start()">
            <td style="padding:2.0%;width:22%;vertical-align:middle;min-width:180px">
              <div class="one" style="width:auto; height:auto; max-width:100%; position: relative;">
                <img src="/images/2022/2022_maskgrasp.jpg" width="160" style="display: block; width: 100%; height: auto;">
                <div class="two" id="maskgrasp_mouseover" style="width:100%; height:100%; position: absolute; top: 0; left: 0; opacity: 0; transition: opacity 0.3s ease-in-out;">
                  
                    <img src="/images/2022/2022_maskgrasp.gif" width="160" style="display: block; width: 100%; height: auto;">
                  
                </div>
              </div>

              <script type="text/javascript">
                function maskgrasp_start() {
                  const mouseoverDiv = document.getElementById('maskgrasp_mouseover');
                  if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "1";

                  
                }

                function maskgrasp_stop() {
                  const mouseoverDiv = document.getElementById('maskgrasp_mouseover');
                   if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "0";

                  // Only try to pause video if video_over exists for this post
                  
                }
                // Initial call to ensure the mouseover content is hidden on page load
                maskgrasp_stop();
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="https://ieeexplore.ieee.org/document/9982130"><h3>MasKGrasp: Mask-based Grasping for Scenes with Multiple General Real-world Objects</h3></a>
              <br>
              Junho Lee, <b>Junhwa Hur</b>, Inwoo Hwang, and Young Min Kim
              <br>
              
              <em>IROS</em>, 2022
              <br>
              <a href="https://ieeexplore.ieee.org/document/9982130">paper</a> / 
              <a href="https://www.youtube.com/watch?v=iWvstHPu97Y">video</a>
              <p>We introduce a mask-based grasping
method that discerns multiple transparent and opaque objects and finds the optimal grasp position avoiding clutter.</p>

            </td>
          </tr>
        
          <tr onmouseout="multimonosf_stop()" onmouseover="multimonosf_start()">
            <td style="padding:2.0%;width:22%;vertical-align:middle;min-width:180px">
              <div class="one" style="width:auto; height:auto; max-width:100%; position: relative;">
                <img src="/images/2021/2021_multimonosf.jpg" width="160" style="display: block; width: 100%; height: auto;">
                <div class="two" id="multimonosf_mouseover" style="width:100%; height:100%; position: absolute; top: 0; left: 0; opacity: 0; transition: opacity 0.3s ease-in-out;">
                  
                    <img src="/images/2021/2021_multimonosf.gif" width="160" style="display: block; width: 100%; height: auto;">
                  
                </div>
              </div>

              <script type="text/javascript">
                function multimonosf_start() {
                  const mouseoverDiv = document.getElementById('multimonosf_mouseover');
                  if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "1";

                  
                }

                function multimonosf_stop() {
                  const mouseoverDiv = document.getElementById('multimonosf_mouseover');
                   if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "0";

                  // Only try to pause video if video_over exists for this post
                  
                }
                // Initial call to ensure the mouseover content is hidden on page load
                multimonosf_stop();
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Hur_Self-Supervised_Multi-Frame_Monocular_Scene_Flow_CVPR_2021_paper.pdf"><h3>Self-Supervised Multi-Frame Monocular Scene Flow</h3></a>
              <br>
              <b>Junhwa Hur</b> and Stefan Roth
              <br>
              
              <em>CVPR</em>, 2021
              <br>
              <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Hur_Self-Supervised_Multi-Frame_Monocular_Scene_Flow_CVPR_2021_paper.pdf">paper</a> / 
              <a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Hur_Self-Supervised_Multi-Frame_Monocular_CVPR_2021_supplemental.pdf">supp</a> / 
              <a href="https://arxiv.org/abs/2105.02216">arxiv</a> / 
              <a href="https://github.com/visinf/multi-mono-sf">code</a> / 
              <a href="https://www.youtube.com/watch?v=nFLfm3YZ_RI">talk</a>
              <p>In the multi-frame setup, using ConvLSTM + warping hidden states improves the accuracy and the temporal consistency of the monocular scene flow.</p>

            </td>
          </tr>
        
          <tr onmouseout="monosf_stop()" onmouseover="monosf_start()">
            <td style="padding:2.0%;width:22%;vertical-align:middle;min-width:180px">
              <div class="one" style="width:auto; height:auto; max-width:100%; position: relative;">
                <img src="/images/2020/2020_monosf.jpg" width="160" style="display: block; width: 100%; height: auto;">
                <div class="two" id="monosf_mouseover" style="width:100%; height:100%; position: absolute; top: 0; left: 0; opacity: 0; transition: opacity 0.3s ease-in-out;">
                  
                    <img src="/images/2020/2020_monosf.gif" width="160" style="display: block; width: 100%; height: auto;">
                  
                </div>
              </div>

              <script type="text/javascript">
                function monosf_start() {
                  const mouseoverDiv = document.getElementById('monosf_mouseover');
                  if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "1";

                  
                }

                function monosf_stop() {
                  const mouseoverDiv = document.getElementById('monosf_mouseover');
                   if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "0";

                  // Only try to pause video if video_over exists for this post
                  
                }
                // Initial call to ensure the mouseover content is hidden on page load
                monosf_stop();
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Hur_Self-Supervised_Monocular_Scene_Flow_Estimation_CVPR_2020_paper.pdf"><h3>Self-Supervised Monocular Scene Flow Estimation</h3></a>
              <br>
              <b>Junhwa Hur</b> and Stefan Roth
              <br>
              
              <em>CVPR</em>, 2020<font color="#FA4841"><b>&nbsp;&nbsp;Oral presentation</b></font>
              <br>
              <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Hur_Self-Supervised_Monocular_Scene_Flow_Estimation_CVPR_2020_paper.pdf">paper</a> / 
              <a href="https://openaccess.thecvf.com/content_CVPR_2020/supplemental/Hur_Self-Supervised_Monocular_Scene_CVPR_2020_supplemental.pdf">supp</a> / 
              <a href="https://arxiv.org/abs/2004.04143">arxiv</a> / 
              <a href="https://github.com/visinf/self-mono-sf">code</a> / 
              <a href="https://www.youtube.com/watch?v=1lR6PQO82lc&feature=youtu.be">talk</a>
              <p>We propose to estimate scene flow from only two monocular images with a CNN trained in a self-supervised manner.</p>

            </td>
          </tr>
        
          <tr onmouseout="mhm_stop()" onmouseover="mhm_start()">
            <td style="padding:2.0%;width:22%;vertical-align:middle;min-width:180px">
              <div class="one" style="width:auto; height:auto; max-width:100%; position: relative;">
                <img src="/images/2020/2020_mhm.jpg" width="160" style="display: block; width: 100%; height: auto;">
                <div class="two" id="mhm_mouseover" style="width:100%; height:100%; position: absolute; top: 0; left: 0; opacity: 0; transition: opacity 0.3s ease-in-out;">
                  
                    <img src="/images/2020/2020_mhm.jpg" width="160" style="display: block; width: 100%; height: auto;">
                  
                </div>
              </div>

              <script type="text/javascript">
                function mhm_start() {
                  const mouseoverDiv = document.getElementById('mhm_mouseover');
                  if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "1";

                  
                }

                function mhm_stop() {
                  const mouseoverDiv = document.getElementById('mhm_mouseover');
                   if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "0";

                  // Only try to pause video if video_over exists for this post
                  
                }
                // Initial call to ensure the mouseover content is hidden on page load
                mhm_stop();
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="https://arxiv.org/abs/2004.02853"><h3>Optical Flow Estimation in the Deep Learning Age</h3></a>
              <br>
              <b>Junhwa Hur</b> and Stefan Roth
              <br>
              
              <em>Modelling Human Motion, N. Noceti, A. Sciutti and F. Rea, Eds., Springer</em>, 2020
              <br>
              <a href="https://link.springer.com/chapter/10.1007/978-3-030-46732-6_7">paper</a> / 
              <a href="https://arxiv.org/abs/2004.02853">arxiv</a>
              <p>As a book chapter, we comprehensively review CNN-based approaches to optical flow and their technical details, including un-/semi-supervised methods.</p>

            </td>
          </tr>
        
          <tr onmouseout="irr_stop()" onmouseover="irr_start()">
            <td style="padding:2.0%;width:22%;vertical-align:middle;min-width:180px">
              <div class="one" style="width:auto; height:auto; max-width:100%; position: relative;">
                <img src="/images/2019/2019_irr.png" width="160" style="display: block; width: 100%; height: auto;">
                <div class="two" id="irr_mouseover" style="width:100%; height:100%; position: absolute; top: 0; left: 0; opacity: 0; transition: opacity 0.3s ease-in-out;">
                  
                    <img src="/images/2019/2019_irr.gif" width="160" style="display: block; width: 100%; height: auto;">
                  
                </div>
              </div>

              <script type="text/javascript">
                function irr_start() {
                  const mouseoverDiv = document.getElementById('irr_mouseover');
                  if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "1";

                  
                }

                function irr_stop() {
                  const mouseoverDiv = document.getElementById('irr_mouseover');
                   if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "0";

                  // Only try to pause video if video_over exists for this post
                  
                }
                // Initial call to ensure the mouseover content is hidden on page load
                irr_stop();
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Hur_Iterative_Residual_Refinement_for_Joint_Optical_Flow_and_Occlusion_Estimation_CVPR_2019_paper.pdf"><h3>Iterative Residual Refinement for Joint Optical Flow and Occlusion Estimation</h3></a>
              <br>
              <b>Junhwa Hur</b> and Stefan Roth
              <br>
              
              <em>CVPR</em>, 2019
              <br>
              <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Hur_Iterative_Residual_Refinement_for_Joint_Optical_Flow_and_Occlusion_Estimation_CVPR_2019_paper.pdf">paper</a> / 
              <a href="http://openaccess.thecvf.com/content_CVPR_2019/supplemental/Hur_Iterative_Residual_Refinement_CVPR_2019_supplemental.pdf">supp</a> / 
              <a href="https://arxiv.org/abs/1904.05290">arxiv</a> / 
              <a href="https://github.com/visinf/irr">code</a>
              <p>An iterative residual refinement scheme based on weight sharing reduces the number of network parameters and improves the accuracy of optical flow and occlusion.</p>

            </td>
          </tr>
        
          <tr onmouseout="unflow_stop()" onmouseover="unflow_start()">
            <td style="padding:2.0%;width:22%;vertical-align:middle;min-width:180px">
              <div class="one" style="width:auto; height:auto; max-width:100%; position: relative;">
                <img src="/images/2018/2018_unflow_img.jpg" width="160" style="display: block; width: 100%; height: auto;">
                <div class="two" id="unflow_mouseover" style="width:100%; height:100%; position: absolute; top: 0; left: 0; opacity: 0; transition: opacity 0.3s ease-in-out;">
                  
                    <img src="/images/2018/2018_unflow_flow.jpg" width="160" style="display: block; width: 100%; height: auto;">
                  
                </div>
              </div>

              <script type="text/javascript">
                function unflow_start() {
                  const mouseoverDiv = document.getElementById('unflow_mouseover');
                  if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "1";

                  
                }

                function unflow_stop() {
                  const mouseoverDiv = document.getElementById('unflow_mouseover');
                   if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "0";

                  // Only try to pause video if video_over exists for this post
                  
                }
                // Initial call to ensure the mouseover content is hidden on page load
                unflow_stop();
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="https://ojs.aaai.org/index.php/AAAI/article/view/12276"><h3>UnFlow: Unsupervised Learning of Optical Flow with a Bidirectional Census Loss</h3></a>
              <br>
              Simon Meister, <b>Junhwa Hur</b> and Stefan Roth
              <br>
              
              <em>AAAI</em>, 2018<font color="#FA4841"><b>&nbsp;&nbsp;Oral presentation</b></font>
              <br>
              <a href="https://ojs.aaai.org/index.php/AAAI/article/view/12276">paper</a> / 
              <a href="https://arxiv.org/abs/1711.07837">arxiv</a> / 
              <a href="https://github.com/simonmeister/UnFlow">code</a> / 
              <a href="http://simonmeister.org/files/slides_unflow_aaai18.pdf">slide</a>
              <p>By directly training on the target domain with an improved unsupervised loss, our method outperforms a supervised method that is pre-trained on a synthetic dataset.</p>

            </td>
          </tr>
        
          <tr onmouseout="mirrorflow_stop()" onmouseover="mirrorflow_start()">
            <td style="padding:2.0%;width:22%;vertical-align:middle;min-width:180px">
              <div class="one" style="width:auto; height:auto; max-width:100%; position: relative;">
                <img src="/images/2017/2017_mirrorflow.png" width="160" style="display: block; width: 100%; height: auto;">
                <div class="two" id="mirrorflow_mouseover" style="width:100%; height:100%; position: absolute; top: 0; left: 0; opacity: 0; transition: opacity 0.3s ease-in-out;">
                  
                    <img src="/images/2017/2017_mirrorflow_occ.png" width="160" style="display: block; width: 100%; height: auto;">
                  
                </div>
              </div>

              <script type="text/javascript">
                function mirrorflow_start() {
                  const mouseoverDiv = document.getElementById('mirrorflow_mouseover');
                  if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "1";

                  
                }

                function mirrorflow_stop() {
                  const mouseoverDiv = document.getElementById('mirrorflow_mouseover');
                   if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "0";

                  // Only try to pause video if video_over exists for this post
                  
                }
                // Initial call to ensure the mouseover content is hidden on page load
                mirrorflow_stop();
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Hur_MirrorFlow_Exploiting_Symmetries_ICCV_2017_paper.pdf"><h3>MirrorFlow: Exploiting Symmetries in Joint Optical Flow and Occlusion Estimation</h3></a>
              <br>
              <b>Junhwa Hur</b> and Stefan Roth
              <br>
              
              <em>ICCV</em>, 2017
              <br>
              <a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Hur_MirrorFlow_Exploiting_Symmetries_ICCV_2017_paper.pdf">paper</a> / 
              <a href="http://openaccess.thecvf.com/content_ICCV_2017/supplemental/Hur_MirrorFlow_Exploiting_Symmetries_ICCV_2017_supplemental.pdf">supp</a> / 
              <a href="https://arxiv.org/abs/1708.05355">arxiv</a> / 
              <a href="https://bitbucket.org/visinf/projects-2017-mirrorflow">code</a> / 
              <a href="/pdfs/2017_iccv_poster.pdf">poster</a>
              <p>The chicken-and-egg relationship between optical flow and occlusion can be nicely formulated through exploiting the symmetry properties they have.</p>

            </td>
          </tr>
        
          <tr onmouseout="jfs_stop()" onmouseover="jfs_start()">
            <td style="padding:2.0%;width:22%;vertical-align:middle;min-width:180px">
              <div class="one" style="width:auto; height:auto; max-width:100%; position: relative;">
                <img src="/images/2016/2016_jfs_input.jpg" width="160" style="display: block; width: 100%; height: auto;">
                <div class="two" id="jfs_mouseover" style="width:100%; height:100%; position: absolute; top: 0; left: 0; opacity: 0; transition: opacity 0.3s ease-in-out;">
                  
                    <img src="/images/2016/2016_jfs_output.jpg" width="160" style="display: block; width: 100%; height: auto;">
                  
                </div>
              </div>

              <script type="text/javascript">
                function jfs_start() {
                  const mouseoverDiv = document.getElementById('jfs_mouseover');
                  if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "1";

                  
                }

                function jfs_stop() {
                  const mouseoverDiv = document.getElementById('jfs_mouseover');
                   if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "0";

                  // Only try to pause video if video_over exists for this post
                  
                }
                // Initial call to ensure the mouseover content is hidden on page load
                jfs_stop();
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="https://arxiv.org/pdf/1607.07716v1.pdf"><h3>Joint Optical Flow and Temporally Consistent Semantic Segmentation</h3></a>
              <br>
              <b>Junhwa Hur</b> and Stefan Roth
              <br>
              
              <em>ECCV Workshop on Computer Vision for Road Scene Understanding and Autonomous Driving (ECCVW)</em>, 2016<font color="#FA4841"><b>&nbsp;&nbsp;Best paper award</b></font>
              <br>
              <a href="https://doi.org/10.1007/978-3-319-46604-0_12">paper</a> / 
              <a href="https://arxiv.org/abs/1607.07716">arxiv</a> / 
              <a href="/pdfs/2016_eccvws_poster.pdf">poster</a>
              <p>We propose a method for the joint estimation of optical flow and temporally consistent semantic segmentation, which closely connects the two problem domains and allows each task leverage the other.</p>

            </td>
          </tr>
        
          <tr onmouseout="gdsp_stop()" onmouseover="gdsp_start()">
            <td style="padding:2.0%;width:22%;vertical-align:middle;min-width:180px">
              <div class="one" style="width:auto; height:auto; max-width:100%; position: relative;">
                <img src="/images/2015/2015_gdsp.jpg" width="160" style="display: block; width: 100%; height: auto;">
                <div class="two" id="gdsp_mouseover" style="width:100%; height:100%; position: absolute; top: 0; left: 0; opacity: 0; transition: opacity 0.3s ease-in-out;">
                  
                    <img src="/images/2015/2015_gdsp.gif" width="160" style="display: block; width: 100%; height: auto;">
                  
                </div>
              </div>

              <script type="text/javascript">
                function gdsp_start() {
                  const mouseoverDiv = document.getElementById('gdsp_mouseover');
                  if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "1";

                  
                }

                function gdsp_stop() {
                  const mouseoverDiv = document.getElementById('gdsp_mouseover');
                   if (!mouseoverDiv) return;

                  mouseoverDiv.style.opacity = "0";

                  // Only try to pause video if video_over exists for this post
                  
                }
                // Initial call to ensure the mouseover content is hidden on page load
                gdsp_stop();
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Hur_Generalized_Deformable_Spatial_2015_CVPR_paper.pdf"><h3>Generalized Deformable Spatial Pyramid: Geometry-Preserving Dense Correspondence Estimation</h3></a>
              <br>
              <b>Junhwa Hur</b>, Hwasup Lim, Changsoo Park, and Sang Chul Ahn
              <br>
              
              <em>CVPR</em>, 2015
              <br>
              <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Hur_Generalized_Deformable_Spatial_2015_CVPR_paper.pdf">paper</a> / 
              <a href="http://openaccess.thecvf.com/content_cvpr_2015/supplemental/Hur_Generalized_Deformable_Spatial_2015_CVPR_supplemental.pdf">supp</a> / 
              <a href="https://sites.google.com/site/hurjunhwa/research/gdsp">project</a> / 
              <a href="https://www.youtube.com/watch?v=74O5LiiXI6w">video</a>
              <p>A piece-wise similarity transform along pyramid levels can approximate a non-rigid deformation in the semantic matching problem.</p>

            </td>
          </tr>
        
        </table>

        <br>
        <br>
        <br>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Design / source code from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron</a>'s / <a style="font-size:small;" href="https://leonidk.com/">Leonid Keselman</a>'s website
              </p>
            </td>
          </tr>
        </table>
      </td>
    </tr>
  </table>
</body>

</html>

