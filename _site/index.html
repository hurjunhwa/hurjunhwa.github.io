<!DOCTYPE HTML>
<html lang="en">

<head>
  <title>Junhwa Hur</title>

  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">

  <meta name="author" content="Junhwa Hur" />
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="/style.css" />
  <link rel="canonical" href="http://localhost:4000/">
  <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-FN8RP63YW2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-FN8RP63YW2');
</script>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr style="padding:0px">
            <td style="padding:2.5%;width:70%;vertical-align:middle">
              <h1>
                Junhwa Hur
              </h1>
              <p>I had been working as a Ph.D. candidate in <a href="http://www.visinf.tu-darmstadt.de/visinf/news/index.en.jsp">Visual Inference group</a> at <a href="http://www.tu-darmstadt.de/index.en.jsp">Technische Universität Darmstadt</a>,
under the supervision of <a href="https://www.visinf.tu-darmstadt.de/visinf/team_members/sroth/sroth.en.jsp">Prof. Stefan Roth Ph.D.</a> since 2015. I did my MS at <a href="https://en.snu.ac.kr/index.html">Seoul National University</a>, researching on computer vision system for autonomous driving, adviced by <a href="http://vi.snu.ac.kr/xe/">Prof. Seung-Woo Seo Ph.D.</a>
              </p>
              <p style="text-align:center">
                <a href="mailto:junhwa.hur@gmail.com">Email</a> &nbsp;/&nbsp;
                <a href="/pdfs/cv.pdf">CV</a>  &nbsp;/&nbsp;
                <a href="https://scholar.google.com/citations?user=z4dNJdkAAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                <a href="https://github.com/hurjunhwa">Github</a> &nbsp;/&nbsp;
                <a href="https://www.linkedin.com/in/junhwa-hur"> LinkedIn </a>
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/profile_img.png">
            </td>
          </tr>
        </table>


<!-- News -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>News</h2>
              <ul>
              <li>11/2020: Chosen as one of 66 outstanding reviewers of ACCV 2020.</li>
              <li>08/2020: Chosen as one of 216 outstanding reviewers of ECCV 2020 (out of a total of 2830 reviewers).</li>
              <li>06/2020: Chosen as one of 141 outstanding reviewers of CVPR 2020 (out of a total of 3664 reviewers).</li>
              <li>02/2020: Our paper on Monocular scene flow estimation has been accepted at CVPR 2020 as an oral presentation.</li>
              <li>12/2019: Our UnFlow paper received the Best Paper Award at Computer Graphik Abend 2019, Impact on Science.</li>
              <li>06/2019: Chosen as one of 246 outstanding reviewers of CVPR 2019 (out of a total of over 2800 reviewers).</li></ul>
            </td>
          </tr>
        </table>

<!-- Research -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Research</h2>
              <p>
                I'm interested in computer vision and machine learning, especially understanding dynamic scene from a monocular video.
              </p>
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          
          <tr onmouseout="monosf_stop()" onmouseover="monosf_start()">
            <td style="padding:2.0%;width:25%;vertical-align:middle">
              <div class="one" style="width:auto; height:auto; max-width:100%;">
                <div class="two" style="width:auto; height:auto; max-width:100%;" id='monosf_image'>
                  <img src=/images/2020_monosf.png width="160"></div>
                <img src=/images/2020_monosf.png width="160">
              </div>
              <script type="text/javascript">
                function monosf_start() {
                  document.getElementById('monosf_image').style.opacity = "1";
                }
                function monosf_stop() {
                  document.getElementById('monosf_image').style.opacity = "0";
                }
                monosf_stop()
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Hur_Self-Supervised_Monocular_Scene_Flow_Estimation_CVPR_2020_paper.pdf"><h3>Self-Supervised Monocular Scene Flow Estimation</h3></a>
              <br>
              <b>Junhwa Hur</b> and Stefan Roth
              <br>
              <em>CVPR</em>, 2020<font color="#FA4841"><b>&nbsp;&nbsp;Oral presentation</b></font>
              <br>
              <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Hur_Self-Supervised_Monocular_Scene_Flow_Estimation_CVPR_2020_paper.pdf">paper</a>/ 
              <a href="https://openaccess.thecvf.com/content_CVPR_2020/supplemental/Hur_Self-Supervised_Monocular_Scene_CVPR_2020_supplemental.pdf">supp</a>/ 
              <a href="https://arxiv.org/abs/2004.04143">arxiv</a>/ 
              <a href="https://github.com/visinf/self-mono-sf">code</a>/ 
              <a href="https://www.youtube.com/watch?v=1lR6PQO82lc&feature=youtu.be">talk</a>
              <p></p>
              <p>We propose to estimate scene flow from only two monocular images with a CNN trained in a self-supervised manner.</p>

            </td>
          </tr>
          
          <tr onmouseout="mhm_stop()" onmouseover="mhm_start()">
            <td style="padding:2.0%;width:25%;vertical-align:middle">
              <div class="one" style="width:auto; height:auto; max-width:100%;">
                <div class="two" style="width:auto; height:auto; max-width:100%;" id='mhm_image'>
                  <img src=/images/2020_mhm.jpg width="160"></div>
                <img src=/images/2020_mhm.jpg width="160">
              </div>
              <script type="text/javascript">
                function mhm_start() {
                  document.getElementById('mhm_image').style.opacity = "1";
                }
                function mhm_stop() {
                  document.getElementById('mhm_image').style.opacity = "0";
                }
                mhm_stop()
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="https://arxiv.org/abs/2004.02853"><h3>Optical Flow Estimation in the Deep Learning Age</h3></a>
              <br>
              <b>Junhwa Hur</b> and Stefan Roth
              <br>
              <em>Modelling Human Motion, N. Noceti, A. Sciutti and F. Rea, Eds., Springer</em>, 2020
              <br>
              <a href="https://link.springer.com/chapter/10.1007/978-3-030-46732-6_7">paper</a>/ 
              <a href="https://arxiv.org/abs/2004.02853">arxiv</a>
              <p></p>
              <p>As a book chapter, we comprehensively review CNN-based approaches to optical flow and their technical details, including un-/semi-supervised methods.</p>

            </td>
          </tr>
          
          <tr onmouseout="irr_stop()" onmouseover="irr_start()">
            <td style="padding:2.0%;width:25%;vertical-align:middle">
              <div class="one" style="width:auto; height:auto; max-width:100%;">
                <div class="two" style="width:auto; height:auto; max-width:100%;" id='irr_image'>
                  <img src=/images/2019_irr.png width="160"></div>
                <img src=/images/2019_irr.png width="160">
              </div>
              <script type="text/javascript">
                function irr_start() {
                  document.getElementById('irr_image').style.opacity = "1";
                }
                function irr_stop() {
                  document.getElementById('irr_image').style.opacity = "0";
                }
                irr_stop()
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Hur_Iterative_Residual_Refinement_for_Joint_Optical_Flow_and_Occlusion_Estimation_CVPR_2019_paper.pdf"><h3>Iterative Residual Refinement for Joint Optical Flow and Occlusion Estimation</h3></a>
              <br>
              <b>Junhwa Hur</b> and Stefan Roth
              <br>
              <em>CVPR</em>, 2019
              <br>
              <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Hur_Iterative_Residual_Refinement_for_Joint_Optical_Flow_and_Occlusion_Estimation_CVPR_2019_paper.pdf">paper</a>/ 
              <a href="http://openaccess.thecvf.com/content_CVPR_2019/supplemental/Hur_Iterative_Residual_Refinement_CVPR_2019_supplemental.pdf">supp</a>/ 
              <a href="https://arxiv.org/abs/1904.05290">arxiv</a>/ 
              <a href="https://github.com/visinf/irr">code</a>
              <p></p>
              <p>Iterative residual refinement scheme based on weight sharing reduces the number of network parameters and improves the accuracy for optical flow and occlusion.</p>

            </td>
          </tr>
          
          <tr onmouseout="unflow_stop()" onmouseover="unflow_start()">
            <td style="padding:2.0%;width:25%;vertical-align:middle">
              <div class="one" style="width:auto; height:auto; max-width:100%;">
                <div class="two" style="width:auto; height:auto; max-width:100%;" id='unflow_image'>
                  <img src=/images/2018_unflow.png width="160"></div>
                <img src=/images/2018_unflow.png width="160">
              </div>
              <script type="text/javascript">
                function unflow_start() {
                  document.getElementById('unflow_image').style.opacity = "1";
                }
                function unflow_stop() {
                  document.getElementById('unflow_image').style.opacity = "0";
                }
                unflow_stop()
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewFile/16502/16319"><h3>UnFlow: Unsupervised Learning of Optical Flow with a Bidirectional Census Loss</h3></a>
              <br>
              Simon Meister, <b>Junhwa Hur</b> and Stefan Roth
              <br>
              <em>AAAI</em>, 2018<font color="#FA4841"><b>&nbsp;&nbsp;Oral presentation</b></font>
              <br>
              <a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewFile/16502/16319">paper</a>/ 
              <a href="https://arxiv.org/pdf/1711.07837.pdf">arxiv</a>/ 
              <a href="https://github.com/simonmeister/UnFlow">code</a>/ 
              <a href="http://simonmeister.org/files/slides_unflow_aaai18.pdf">slide</a>
              <p></p>
              <p>Directly training on the target domain with a better unsupervised loss can outperform the supervised pre-training on synthetic dataset.</p>

            </td>
          </tr>
          
          <tr onmouseout="mirrorflow_stop()" onmouseover="mirrorflow_start()">
            <td style="padding:2.0%;width:25%;vertical-align:middle">
              <div class="one" style="width:auto; height:auto; max-width:100%;">
                <div class="two" style="width:auto; height:auto; max-width:100%;" id='mirrorflow_image'>
                  <img src=/images/2017_mirrorflow_occ.png width="160"></div>
                <img src=/images/2017_mirrorflow.png width="160">
              </div>
              <script type="text/javascript">
                function mirrorflow_start() {
                  document.getElementById('mirrorflow_image').style.opacity = "1";
                }
                function mirrorflow_stop() {
                  document.getElementById('mirrorflow_image').style.opacity = "0";
                }
                mirrorflow_stop()
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Hur_MirrorFlow_Exploiting_Symmetries_ICCV_2017_paper.pdf"><h3>MirrorFlow: Exploiting Symmetries in Joint Optical Flow and Occlusion Estimation</h3></a>
              <br>
              <b>Junhwa Hur</b> and Stefan Roth
              <br>
              <em>ICCV</em>, 2017
              <br>
              <a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Hur_MirrorFlow_Exploiting_Symmetries_ICCV_2017_paper.pdf">paper</a>/ 
              <a href="http://openaccess.thecvf.com/content_ICCV_2017/supplemental/Hur_MirrorFlow_Exploiting_Symmetries_ICCV_2017_supplemental.pdf">supp</a>/ 
              <a href="https://arxiv.org/abs/1708.05355">arxiv</a>/ 
              <a href="https://bitbucket.org/visinf/projects-2017-mirrorflow">code</a>/ 
              <a href="/pdfs/2017_iccv_poster.pdf">poster</a>
              <p></p>
              <p>The chicken-and-egg relationship between optical flow and occlusion can be nicely formulated through exploiting the symmetry properties they have.</p>

            </td>
          </tr>
          
          <tr onmouseout="jfs_stop()" onmouseover="jfs_start()">
            <td style="padding:2.0%;width:25%;vertical-align:middle">
              <div class="one" style="width:auto; height:auto; max-width:100%;">
                <div class="two" style="width:auto; height:auto; max-width:100%;" id='jfs_image'>
                  <img src=/images/2016_jfs.png width="160"></div>
                <img src=/images/2016_jfs.png width="160">
              </div>
              <script type="text/javascript">
                function jfs_start() {
                  document.getElementById('jfs_image').style.opacity = "1";
                }
                function jfs_stop() {
                  document.getElementById('jfs_image').style.opacity = "0";
                }
                jfs_stop()
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="https://arxiv.org/pdf/1607.07716v1.pdf"><h3>Joint Optical Flow and Temporally Consistent Semantic Segmentation</h3></a>
              <br>
              <b>Junhwa Hur</b> and Stefan Roth
              <br>
              <em>ECCV Workshop on Computer Vision for Road Scene Understanding and Autonomous Driving (ECCVW)</em>, 2016<font color="#FA4841"><b>&nbsp;&nbsp;Best paper award</b></font>
              <br>
              <a href="https://doi.org/10.1007/978-3-319-46604-0_12">paper</a>/ 
              <a href="https://arxiv.org/pdf/1607.07716v1.pdf">arxiv</a>/ 
              <a href="/pdfs/2016_eccvws_poster.pdf">poster</a>
              <p></p>
              <p>Optical flow and semantic segmentation can mutually leverage each other.</p>

            </td>
          </tr>
          
          <tr onmouseout="gdsp_stop()" onmouseover="gdsp_start()">
            <td style="padding:2.0%;width:25%;vertical-align:middle">
              <div class="one" style="width:auto; height:auto; max-width:100%;">
                <div class="two" style="width:auto; height:auto; max-width:100%;" id='gdsp_image'>
                  <img src=/images/2015_gdsp.png width="160"></div>
                <img src=/images/2015_gdsp.png width="160">
              </div>
              <script type="text/javascript">
                function gdsp_start() {
                  document.getElementById('gdsp_image').style.opacity = "1";
                }
                function gdsp_stop() {
                  document.getElementById('gdsp_image').style.opacity = "0";
                }
                gdsp_stop()
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Hur_Generalized_Deformable_Spatial_2015_CVPR_paper.pdf"><h3>Generalized Deformable Spatial Pyramid: Geometry-Preserving Dense Correspondence Estimation</h3></a>
              <br>
              <b>Junhwa Hur</b>, Hwasup Lim, Changsoo Park, and Sang Chul Ahn
              <br>
              <em>CVPR</em>, 2015
              <br>
              <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Hur_Generalized_Deformable_Spatial_2015_CVPR_paper.pdf">paper</a>/ 
              <a href="http://openaccess.thecvf.com/content_cvpr_2015/supplemental/Hur_Generalized_Deformable_Spatial_2015_CVPR_supplemental.pdf">supp</a>/ 
              <a href="https://sites.google.com/site/hurjunhwa/research/gdsp">project</a>/ 
              <a href="https://www.youtube.com/watch?v=74O5LiiXI6w">video</a>
              <p></p>
              <p>Piece-wise similarity transform through pyramid levels can handle non-rigid deformation in semantic matching.</p>

            </td>
          </tr>
          
          <tr onmouseout="3ddsp_stop()" onmouseover="3ddsp_start()">
            <td style="padding:2.0%;width:25%;vertical-align:middle">
              <div class="one" style="width:auto; height:auto; max-width:100%;">
                <div class="two" style="width:auto; height:auto; max-width:100%;" id='3ddsp_image'>
                  <img src=/images/2014_3ddsp.png width="160"></div>
                <img src=/images/2014_3ddsp.png width="160">
              </div>
              <script type="text/javascript">
                function 3ddsp_start() {
                  document.getElementById('3ddsp_image').style.opacity = "1";
                }
                function 3ddsp_stop() {
                  document.getElementById('3ddsp_image').style.opacity = "0";
                }
                3ddsp_stop()
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="https://doi.org/10.1007/978-3-319-14249-4_12"><h3>3D Deformable Spatial Pyramid for Dense 3D Motion Flow of Deformable Object</h3></a>
              <br>
              <b>Junhwa Hur</b>, Hwasup Lim, and Sang Chul Ahn
              <br>
              <em>International Symposium on Visual Computing (ISVC)</em>, 2014<font color="#FA4841"><b>&nbsp;&nbsp;Oral presentation</b></font>
              <br>
              <a href="https://doi.org/10.1007/978-3-319-14249-4_12">paper</a>/ 
              <a href="https://sites.google.com/site/hurjunhwa/research/3d_dsp_14">project</a>
              <p></p>
              

            </td>
          </tr>
          
          <tr onmouseout="iv2014_stop()" onmouseover="iv2014_start()">
            <td style="padding:2.0%;width:25%;vertical-align:middle">
              <div class="one" style="width:auto; height:auto; max-width:100%;">
                <div class="two" style="width:auto; height:auto; max-width:100%;" id='iv2014_image'>
                  <img src=/images/2014_iv.png width="160"></div>
                <img src=/images/2014_iv.png width="160">
              </div>
              <script type="text/javascript">
                function iv2014_start() {
                  document.getElementById('iv2014_image').style.opacity = "1";
                }
                function iv2014_stop() {
                  document.getElementById('iv2014_image').style.opacity = "0";
                }
                iv2014_stop()
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="http://dx.doi.org/10.1109/IVS.2014.6856537"><h3>Multi-lane Detection based on Accurate Geometric Lane Estimation in Highway Scenarios</h3></a>
              <br>
              Seung-Nam Kang, Soo-Mok Lee, <b>Junhwa Hur</b>, and Seung-Woo Seo
              <br>
              <em>Intelligent Vehicles Symposium (IV)</em>, 2014
              <br>
              <a href="http://dx.doi.org/10.1109/IVS.2014.6856537">paper</a>/ 
              <a href="https://www.youtube.com/watch?v=RrxSSgeDdzk">video</a>
              <p></p>
              

            </td>
          </tr>
          
          <tr onmouseout="iv2013_stop()" onmouseover="iv2013_start()">
            <td style="padding:2.0%;width:25%;vertical-align:middle">
              <div class="one" style="width:auto; height:auto; max-width:100%;">
                <div class="two" style="width:auto; height:auto; max-width:100%;" id='iv2013_image'>
                  <img src=/images/2013_iv.png width="160"></div>
                <img src=/images/2013_iv.png width="160">
              </div>
              <script type="text/javascript">
                function iv2013_start() {
                  document.getElementById('iv2013_image').style.opacity = "1";
                }
                function iv2013_stop() {
                  document.getElementById('iv2013_image').style.opacity = "0";
                }
                iv2013_stop()
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="http://dx.doi.org/10.1109/IVS.2013.6629645"><h3>Multi-lane Detection in Urban Driving Environments using Conditional Random Fields</h3></a>
              <br>
              <b>Junhwa Hur</b>, Seung-Nam Kang, and Seung-Woo Seo
              <br>
              <em>Intelligent Vehicles Symposium (IV)</em>, 2013
              <br>
              <a href="http://dx.doi.org/10.1109/IVS.2013.6629645">paper</a>/ 
              <a href="https://sites.google.com/site/hurjunhwa/research/mld_iv13">project</a>/ 
              <a href="https://github.com/hurjunhwa/mld_crf">code</a>/ 
              <a href="https://www.youtube.com/watch?v=8LEUHUdqxag&feature=emb_title&ab_channel=JunhwaHur">video</a>
              <p></p>
              

            </td>
          </tr>
          
          <tr onmouseout="msthesis_stop()" onmouseover="msthesis_start()">
            <td style="padding:2.0%;width:25%;vertical-align:middle">
              <div class="one" style="width:auto; height:auto; max-width:100%;">
                <div class="two" style="width:auto; height:auto; max-width:100%;" id='msthesis_image'>
                  <img src=/images/2013_ms_thesis.jpg width="160"></div>
                <img src=/images/2013_ms_thesis.jpg width="160">
              </div>
              <script type="text/javascript">
                function msthesis_start() {
                  document.getElementById('msthesis_image').style.opacity = "1";
                }
                function msthesis_stop() {
                  document.getElementById('msthesis_image').style.opacity = "0";
                }
                msthesis_stop()
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="/pdfs/2013_ms_thesis.pdf"><h3>Multi-lane Detection in Highway and Urban Driving Environment</h3></a>
              <br>
              <b>Junhwa Hur</b>
              <br>
              <em>Master’s thesis, Seoul National University</em>, 2013
              <br>
              <a href="/pdfs/2013_ms_thesis.pdf">paper</a>/ 
              <a href="https://sites.google.com/site/hurjunhwa/research/mld_highway">project</a>
              <p></p>
              

            </td>
          </tr>
          
        </table>
        <br>
        <br>

<!-- Project -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Project</h2>
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          
          <tr onmouseout="deformable_kist_stop()" onmouseover="deformable_kist_start()">
            <td style="padding:2.0%;width:25%;vertical-align:middle">
              <div class="one" style="width:auto; height:auto; max-width:100%;">
                <div class="two" style="width:auto; height:auto; max-width:100%;" id='deformable_kist_image'>
                  <img src=/images/2015_deformable.png width="160"></div>
                <img src=/images/2015_deformable.png width="160">
              </div>
              <script type="text/javascript">
                function deformable_kist_start() {
                  document.getElementById('deformable_kist_image').style.opacity = "1";
                }
                function deformable_kist_stop() {
                  document.getElementById('deformable_kist_image').style.opacity = "0";
                }
                deformable_kist_stop()
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">
              <a href="https://www.youtube.com/watch?v=tJVxF_mcmZ4"><h3>Deformable Object Modeling</h3></a>
              <br>
              <em>IMRC, Korea Institute of Science and Technology (KIST)</em>, 2015 
              <br>
              <a href="https://www.youtube.com/watch?v=tJVxF_mcmZ4">video</a>
              <p></p>
              <p>Researching on modeling deformable object: pose estimation, correspondence search, and loop closure</p>

            </td>
          </tr>
          
          <tr onmouseout="korea_avc_stop()" onmouseover="korea_avc_start()">
            <td style="padding:2.0%;width:25%;vertical-align:middle">
              <div class="one" style="width:auto; height:auto; max-width:100%;">
                <div class="two" style="width:auto; height:auto; max-width:100%;" id='korea_avc_image'>
                  <img src=/images/2015_korea_avc.png width="160"></div>
                <img src=/images/2015_korea_avc.png width="160">
              </div>
              <script type="text/javascript">
                function korea_avc_start() {
                  document.getElementById('korea_avc_image').style.opacity = "1";
                }
                function korea_avc_stop() {
                  document.getElementById('korea_avc_image').style.opacity = "0";
                }
                korea_avc_stop()
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/site/hurjunhwa/research/korea_avc_13"><h3>Korea Autonomous Vehicle Contest 2013</h3></a>
              <br>
              <em>VILab, Seoul National University</em>, 2013 <font color="#FA4841"><b>&nbsp;&nbsp;2nd-place prize</b></font>
              <br>
              <a href="https://www.youtube.com/watch?v=8j-Ew4paNM0">video</a>/ 
              <a href="https://sites.google.com/site/hurjunhwa/research/korea_avc_13">project</a>
              <p></p>
              <p>Researching on computer vision system for autonomous driving: lane/speed-bump/stop-line detection, camera-lidar sensor fusion</p>

            </td>
          </tr>
          
        </table>
        <br>
        <br>
        <br>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Design / source code from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron</a>'s / <a style="font-size:small;" href="https://leonidk.com/">Leonid Keselman</a>'s website
              </p>
            </td>
          </tr>
        </table>
      </td>
    </tr>
  </table>
</body>

</html>

